{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4185,"status":"ok","timestamp":1682912856966,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"},"user_tz":240},"id":"CQq699ei5QWq","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"ed11d192-53b1-4249-e69c-4fe39b6d6447"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.15.1+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import torch\n","torch.__version__\n","import torchvision\n","torchvision.__version__\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"DENct7YwEyZU","executionInfo":{"status":"ok","timestamp":1682912860721,"user_tz":240,"elapsed":813,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}}},"outputs":[],"source":["from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1682912863416,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"},"user_tz":240},"id":"6SJLisUF5fWa","outputId":"fcf7288f-e529-46ad-8b52-6d51d78c2592"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"O9VXwk4S5aFF","executionInfo":{"status":"ok","timestamp":1682913104886,"user_tz":240,"elapsed":239727,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}}},"outputs":[],"source":["# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","%%capture\n","!pip install pyyaml==5.1\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ySxbMrlT9raa","executionInfo":{"status":"ok","timestamp":1682913581765,"user_tz":240,"elapsed":383,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}}},"outputs":[],"source":["# Import models\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.data import MetadataCatalog\n","from detectron2.utils.visualizer import ColorMode, Visualizer, VisImage\n","from detectron2 import model_zoo"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"LSFc5GXf_XUS","executionInfo":{"status":"ok","timestamp":1682913583369,"user_tz":240,"elapsed":1,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}}},"outputs":[],"source":["# Import plot tools\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from detectron2.structures import ImageList\n","from detectron2.modeling import build_model\n","from detectron2.data import transforms as T"]},{"cell_type":"code","source":["  im = cv2.imread('test.jpg')"],"metadata":{"id":"WckGWwL596Wz","executionInfo":{"status":"ok","timestamp":1682913585055,"user_tz":240,"elapsed":343,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def preprocess_image(cfg, img):\n","    # Check and convert the image format\n","    input_format = cfg.INPUT.FORMAT\n","    if input_format == \"RGB\":\n","        img = img[:, :, ::-1]\n","\n","    # Resize the image according to the configuration\n","    transform_gen = T.ResizeShortestEdge(\n","        [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST],\n","        cfg.INPUT.MAX_SIZE_TEST\n","    )\n","    img = transform_gen.get_transform(img).apply_image(img)\n","\n","    # Convert the image to a tensor and normalize it\n","    img_tensor = torch.Tensor(img.astype(\"float32\").transpose(2, 0, 1))\n","\n","    # Create an ImageList object\n","    image_list = ImageList.from_tensors([img_tensor], model.backbone.size_divisibility)\n","\n","    return image_list\n","\n","images = preprocess_image(cfg, im)\n","device = torch.device(\"cuda:0\")\n","images = images.to(device)"],"metadata":{"id":"5DccVLcsE6cC","executionInfo":{"status":"ok","timestamp":1682913599781,"user_tz":240,"elapsed":427,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.MODEL.DEVICE = \"cuda\"\n","model = build_model(cfg)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzRyqVqzJLC0","executionInfo":{"status":"ok","timestamp":1682917991105,"user_tz":240,"elapsed":969,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"outputId":"d533aba7-8709-439d-aa48-a22782d5f814"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from detectron2.data.transforms import ResizeShortestEdge\n","from torchvision.transforms import ToTensor\n","from detectron2.structures import ImageList\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.MODEL.DEVICE = \"cuda\"\n","model = build_model(cfg)\n","model.eval()\n","x = cv2.imread(\"test.jpg\")\n","import detectron2.data.transforms as T\n","# Preprocess the image\n","aug = T.ResizeShortestEdge(\n","            [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n","        )\n","\n","\n","with torch.no_grad():\n","  height, width = x.shape[:2]\n","  y = aug.get_transform(x).apply_image(x)\n","  y = torch.as_tensor(y.astype(\"float32\").transpose(2, 0, 1))\n","  inputs = {\"image\": y, \"height\": height, \"width\": width}\n","  outputs = model([inputs])\n","  print(outputs[0][\"instances\"].pred_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBq3UW4ptoDY","executionInfo":{"status":"ok","timestamp":1682921433122,"user_tz":240,"elapsed":879,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"outputId":"33122f13-7d6f-4694-94ee-c0bacfcce747"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([], device='cuda:0', dtype=torch.int64)\n"]}]},{"cell_type":"code","source":["cfg = get_cfg()\n","img = cv2.imread('test.jpg')\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.MODEL.DEVICE = \"cuda\"\n","predictor = DefaultPredictor(cfg)\n","predictions = predictor(img)\n","ins = predictions[\"instances\"]\n","print(ins.pred_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXkRyD_v9y8v","executionInfo":{"status":"ok","timestamp":1682918108395,"user_tz":240,"elapsed":1575,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"outputId":"32e7debb-4596-4d5e-e952-dc59dc3cb9f5"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 9], device='cuda:0')\n"]}]},{"cell_type":"code","source":["transform_gen = T.ResizeShortestEdge(\n","    [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",")\n","preprocessed_image = transform_gen.get_transform(im).apply_image(im)\n","preprocessed_image_tensor = torch.Tensor(preprocessed_image.astype(\"float32\").transpose(2, 0, 1))"],"metadata":{"id":"lwiwApppc2LE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images = preprocess_image(cfg, im)\n","step_by_step_preprocessed_image_tensor = images[0]"],"metadata":{"id":"dWDf3xlidKZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Shape of preprocessed_image_tensor: \", preprocessed_image_tensor.shape)\n","print(\"Shape of step_by_step_preprocessed_image_tensor: \", step_by_step_preprocessed_image_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4kS6FLndNFW","executionInfo":{"status":"ok","timestamp":1682899268418,"user_tz":240,"elapsed":325,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"outputId":"43f22c9a-af56-4222-b1ed-6b2df00fc9ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of preprocessed_image_tensor:  torch.Size([3, 750, 1333])\n","Shape of step_by_step_preprocessed_image_tensor:  torch.Size([3, 750, 1333])\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gXxixeDl_eJJ"},"outputs":[],"source":["class Detector:\n","  def __init__(self, model_type = \"OD\", score_thresh = 0.7):\n","    self.cfg = get_cfg()\n","    self.model_type = model_type\n","    self.score_thresh = score_thresh\n","\n","    if model_type == \"OD\":\n","      self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","      self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n","      # self.cfg.MODEL.WEIGHTS = \"OD.pkl\"\n","    elif model_type == \"KP\":\n","      self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n","      self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n","      # self.cfg.MODEL.WEIGHTS = \"KP.pkl\"\n","    elif model_type == \"IS\":\n","      self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","      self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")   \n","      # self.cfg.MODEL.WEIGHTS = \"IS.pkl\"\n","\n","    self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.score_thresh\n","    self.cfg.MODEL.DEVICE = \"cuda\"\n","\n","    self.predictor = DefaultPredictor(self.cfg)\n","\n","  \n","  def onImage(self, imagePath, score=True):\n","    image = cv2.imread(imagePath)\n","    predictions = self.predictor(image)\n","    ins = predictions[\"instances\"]\n","    output = VisImage(image[:,:,::-1])\n","\n","    soldier_found = False\n","    soldier_confidence = 0.0\n","    soldier_index = 0\n","\n","    if self.model_type == \"IS\":\n","      viz = Visualizer(image[:,:,::-1], metadata=MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), instance_mode=ColorMode.SEGMENTATION)\n","\n","      soldier_found = False\n","      soldier_confidence = 0.0\n","      soldier_index = 0\n","\n","      index = 0\n","      while index < len(ins.pred_boxes):\n","        if viz.metadata.thing_classes[ins.pred_classes[index]] == \"person\":\n","\n","          # Select the most confident result\n","          soldier_found = True\n","          soldier_index = index if ins.scores[index].tolist() > soldier_confidence else soldier_index\n","          soldier_confidence = max(soldier_confidence, ins.scores[index].tolist())\n","\n","        index = index + 1\n","\n","      if soldier_found:\n","          # Paint\n","          box = ins.pred_boxes[soldier_index].to('cpu').tensor.tolist()[0]\n","          mask = ins.pred_masks[soldier_index].to('cpu').numpy()\n","          # output = viz.draw_box(box, alpha=1.0, edge_color='r', line_style='-')\n","          output = viz.draw_binary_mask(mask.astype(int), color=None, edge_color='r', text=None, alpha=0.2, area_threshold=10)\n","\n","          # Write Label\n","          label_content = \"Soldier!\" + \" Confidence: \" + str(soldier_confidence)[:4] if score else \"Soldier!\"\n","          output = viz.draw_text(label_content, [0, 0], font_size=40, color='r', horizontal_alignment='left', rotation=0)\n","      else:\n","          label_content = \"Safe!\"\n","          output = viz.draw_text(label_content, [0, 0], font_size=40, color='g', horizontal_alignment='left', rotation=0)\n","    else:\n","      viz = Visualizer(image[:,:,::-1], metadata=MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n","\n","      if self.model_type == \"OD\":\n","        soldier_found = False\n","        soldier_confidence = 0.0\n","        soldier_index = 0\n","\n","        index = 0\n","        while index < len(ins.pred_boxes):\n","          if viz.metadata.thing_classes[ins.pred_classes[index]] == \"person\":\n","            \n","            # Select the most confident result\n","            soldier_found = True\n","            soldier_index = index if ins.scores[index].tolist() > soldier_confidence else soldier_index\n","            soldier_confidence = max(soldier_confidence, ins.scores[index].tolist())\n","\n","          index = index + 1\n","        \n","        if soldier_found:\n","          # Paint\n","          box = ins.pred_boxes[soldier_index].to('cpu').tensor.tolist()[0]\n","          output = viz.draw_box(box, alpha=1.0, edge_color='r', line_style='-')\n","          label_content = \"Soldier!\" + \" Confidence: \" + str(soldier_confidence)[:4] if score else \"Soldier!\"\n","          output = viz.draw_text(label_content, [0, 0], font_size=40, color='r', horizontal_alignment='left', rotation=0)\n","        else:\n","          label_content = \"Safe!\"\n","          output = viz.draw_text(label_content, [0, 0], font_size=40, color='g', horizontal_alignment='left', rotation=0)\n","      elif self.model_type == \"KP\":\n","        soldier_found = False\n","        soldier_confidence = 0.0\n","        soldier_index = 0\n","\n","        index = 0\n","        while index < len(ins.pred_boxes):\n","          if viz.metadata.thing_classes[ins.pred_classes[index]] == \"person\":\n","            # Check confidence\n","            if ins.scores[index].tolist() >= 0.5:\n","              soldier_found = True\n","            soldier_index = index if ins.scores[index].tolist() > soldier_confidence else soldier_index\n","            soldier_confidence = max(soldier_confidence, ins.scores[index].tolist())\n","\n","          index = index + 1\n","        if soldier_found:\n","          # Paint\n","          box = ins.pred_boxes[soldier_index].to('cpu').tensor.tolist()[0]\n","          points = ins.pred_keypoints[soldier_index].to('cpu')\n","          output = viz.draw_box(box, alpha=1.0, edge_color='r', line_style='-')\n","          output = viz.draw_and_connect_keypoints(points)\n","          # Write Label\n","          label_content = \"Soldier!\" + \" Confidence: \" + str(soldier_confidence)[:4] if score else \"Soldier!\"\n","          # output = viz.draw_text(label_content, [0, 0], font_size=40, color='r', horizontal_alignment='left', rotation=0)\n","        else:\n","          label_content = \"Safe!\"\n","          # output = viz.draw_text(label_content, [0, 0], font_size=40, color='g', horizontal_alignment='left', rotation=0)\n","\n","    cv2.imwrite(\"result_\"+self.model_type+\"/\"+imagePath, output.get_image()[:,:,::-1])\n","    cv2.waitKey(0)\n","    return float(str(soldier_confidence)[:4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTOlyUy5CFqc","executionInfo":{"status":"ok","timestamp":1681171817601,"user_tz":240,"elapsed":6855,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6edd861-4954-487b-f209-eeabe6fa921b"},"outputs":[{"output_type":"stream","name":"stderr","text":["model_final_a6e10b.pkl: 237MB [00:00, 263MB/s]                           \n"]}],"source":["detector_1 = Detector(\"KP\", 0.1)"]},{"cell_type":"code","source":["r1 = detector_1.onImage(\"test.jpg\")"],"metadata":{"id":"YOLf3CcZpq4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"cLgY9f20uItL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df1 = pd.read_excel(\"result.xlsx\")\n","df2 = pd.read_excel(\"result_1.xlsx\")"],"metadata":{"id":"aGgHs2t6n48G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2[df2[\"error_type\"] == \"TN\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"3tKXQL-AsOcl","executionInfo":{"status":"ok","timestamp":1673901540487,"user_tz":300,"elapsed":212,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"outputId":"85c2f602-6abd-474d-bb20-93aa6529d389"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id  true_state  prediction_result error_type  rate_1  rate_2  rate_avg\n","0      1           0                0.0         TN       3       3       3.0\n","1      2           0                0.0         TN       3       2       2.5\n","2      3           0                0.0         TN       1       1       1.0\n","3      4           0                0.0         TN       2       2       2.0\n","4      5           0                0.0         TN       3       2       2.5\n","..   ...         ...                ...        ...     ...     ...       ...\n","789  790           0                0.0         TN       2       3       2.5\n","790  791           0                0.0         TN       3       3       3.0\n","791  792           0                0.0         TN       1       1       1.0\n","792  793           0                0.0         TN       2       2       2.0\n","793  794           0                0.0         TN       2       2       2.0\n","\n","[668 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-00532e67-070e-4990-b236-af27c7bd1265\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>true_state</th>\n","      <th>prediction_result</th>\n","      <th>error_type</th>\n","      <th>rate_1</th>\n","      <th>rate_2</th>\n","      <th>rate_avg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>789</th>\n","      <td>790</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>790</th>\n","      <td>791</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>791</th>\n","      <td>792</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>792</th>\n","      <td>793</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>793</th>\n","      <td>794</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>TN</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>668 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00532e67-070e-4990-b236-af27c7bd1265')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-00532e67-070e-4990-b236-af27c7bd1265 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-00532e67-070e-4990-b236-af27c7bd1265');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["index = 1\n","while index < 795:\n","  imagePath = str(index) + \".png\"\n","  r1 = detector_1.onImage(imagePath)\n","  ep1 = \"TN\"\n","  if r1 != 0.0:\n","    ep1 = \"FP\"\n","  df2.at[index-1,'prediction_result']=r1\n","  # df2 = df2.append({'id':index, 'true_state':0, 'prediction_result':r1, 'error_type':ep1, 'rate_1': 0, 'rate_2': 0, 'rate_avg': 0}, ignore_index=True)\n","\n","  index = index + 1"],"metadata":{"id":"w9ASe4O9oKXR","executionInfo":{"status":"ok","timestamp":1673901793162,"user_tz":300,"elapsed":239965,"user":{"displayName":"Shihong Ling","userId":"10299469978812796781"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c590699-fccd-47a9-8051-5a9ddd032af7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]}]},{"cell_type":"code","source":["# df1.to_excel(\"br-soldier.xlsx\") \n","df2.to_excel(\"br-landscape.xlsx\")"],"metadata":{"id":"eX4rzDUwFuaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oqc1ZzBFXnQF"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"1nEwHX6Pnkq_V5qBnikwxCv5qb5t9sz49","authorship_tag":"ABX9TyN7j5w9Yd5c9U0TkmY/FRHj"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}